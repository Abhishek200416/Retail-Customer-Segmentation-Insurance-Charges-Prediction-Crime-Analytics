# Retail-Customer-Segmentation-Insurance-Charges-Prediction-Crime-Analytics
# ğŸ§  ML Mini-Stack â€” Retail Segmentation (K-Means) â€¢ Insurance Regression â€¢ Crime (SVM + Forecast)

Practical, copy-run notebooks/scripts for three real-world ML tasks:

1) **Retail Customer Segmentation** â€” K-Means + **Elbow** + **PCA**  
2) **Insurance Charges Prediction** â€” Linear Regression / Random Forest / (optional) XGBoost  
3) **Crime Analytics** â€” **SVM** classification for crime-prone regions + **Monthly Forecast** with RF

All code is written to be **dataset-schema tolerant** (auto-detects columns when possible) and saves artifacts to `models/` and `outputs/`.

---

## ğŸ“ Repo Layout (suggested)

.
â”œâ”€ notebooks_or_scripts/
â”‚ â”œâ”€ retail_kmeans.ipynb # or .py version with the code you pasted
â”‚ â”œâ”€ insurance_regression.ipynb
â”‚ â””â”€ crime_analytics.ipynb
â”œâ”€ streamlit_app.py # Insurance demo (from README)
â”œâ”€ crime.py # Crime dashboard (from README)
â”œâ”€ data/
â”‚ â”œâ”€ Online Retail.xlsx # or Mall_Customers.csv
â”‚ â”œâ”€ insurance.csv
â”‚ â””â”€ indian_crimes.csv
â”œâ”€ models/ # saved models (auto-created)
â”œâ”€ outputs/ # predictions / labeled CSVs (auto-created)
â””â”€ README.md

yaml
Copy code

> Put your datasets in `data/` or update the paths inside the notebooks/scripts. The loaders will prompt for a path if not found.

---

## ğŸ”§ Environment Setup

```bash
# Python 3.10+ recommended
python -m venv .venv
# Windows PowerShell:
.venv\Scripts\activate

pip install -U pip
pip install numpy pandas scikit-learn matplotlib joblib streamlit

# Optional (speeds up Insurance if installed):
pip install xgboost
ğŸ§© Task A â€” Retail Customer Segmentation (K-Means)
Goal: cluster customers by behavior, choose K via Elbow, visualize clusters using PCA-2D.
Dataset options (either works):

Kaggle â€œMall Customersâ€ style (columns like Age, Annual Income (k$), Spending Score (1-100)), or

UCI-style Online Retail Excel (Invoice-level) â†’ build RFM features per CustomerID.

How it adapts automatically:

If columns contain Age / Income / Spending Score â†’ uses them directly.

Else it assumes Online Retail schema and computes:

Recency (days since last purchase)

Frequency (distinct invoices)

Monetary (Î£ Quantity Ã— UnitPrice, filtered for returns/negatives)

Pipeline:

Load/convert .xlsx â†’ .csv if needed

Build feature table (Age/Income/SpendingScore or RFM)

StandardScaler

Elbow Method (K = 2â€¦10) â†’ choose bend (default K_FINAL = 5, adjust from plot)

Fit K-Means, save labels

PCA(2) plot with cluster colors

Save:

Labeled data â†’ outputs/task2_clusters.csv

Model + Scaler â†’ models/task2_kmeans.joblib, models/task2_scaler.joblib

Feature meta â†’ models/task2_feature_names.json

Datasets:

Mall Customers: https://www.kaggle.com/datasets/yasserh/mall-customers

Online Retail: https://archive.ics.uci.edu/dataset/352/online+retail

In your script, set:

python
Copy code
DATA_PATH = "data/Online Retail.xlsx"   # or "data/Mall_Customers.csv"
ğŸ’¸ Task B â€” Insurance Charges Prediction (Regression)
Goal: predict charges from age, sex, bmi, children, smoker, region.
Models: LinearRegression, RandomForestRegressor, (optional) XGBRegressor
Metrics: MSE & RÂ² with unified preprocessing (ColumnTransformer + OneHotEncoder + StandardScaler).

Steps:

Load data/insurance.csv

Drop junk columns like Unnamed: 0 if present

Split train/test

Train LR, RF, (XGB if installed)

Compare metrics (bar charts for MSE & RÂ²)

Save best-by-MSE pipeline â†’ models/insurance_best.joblib

Dataset:
https://www.kaggle.com/datasets/thedevastator/prediction-of-insurance-charges-using-age-gender

ğŸš€ Quick Streamlit UI (already provided)
Run the simple app to test your trained pipeline:

bash
Copy code
streamlit run streamlit_app.py
The app loads models/insurance_best.joblib

Enter features â†’ click Predict charges â†’ shows estimated amount

ğŸš“ Task C â€” Crime Analytics (SVM + Monthly Forecast)
Classification: Label regions as crime-prone (top quartile of rate) vs not and train an SVM (RBF).
Forecasting: Aggregate monthly totals; train RandomForestRegressor (and a Linear baseline) to forecast.

Pipeline (robust to schema drift):

Normalize columns to lower_snake_case

Parse time (searches common date columns; requires one parseable date) â†’ build year, month

Missing-data impact (Before) bar plot

Clean: map booleans, fix categories, light numeric imputations

Region aggregation (city/district/state) â†’ total_crimes, crimes_per_100k (if population available)

Label crime-prone as top quartile

SVM with scaling â†’ classification report + confusion matrix

Monthly series with lag & rolling features â†’ train/test split â†’ RF vs LR (MSE/RÂ²) + line plot

Persist:

models/crime_svm.joblib

models/crime_trend_rf.joblib

models/feature_columns_trend.json

Missing-data impact (After) bar plot

Dataset (example):
https://www.kaggle.com/datasets/sudhanvahg/indian-crimes-dataset

ğŸš€ Crime Streamlit Dashboard
bash
Copy code
streamlit run crime.py
Tab 1: Enter total_crimes & crimes_per_100k â†’ SVM predicts âš ï¸ Crime-prone / âœ… Safer

Tab 2: Line chart of history + Forecast using the saved RF model

If data/monthly_incidents.csv exists (columns Month, Incidents), app uses it; else, demo series

ğŸ’¾ Outputs & Models
Retail:

outputs/task2_clusters.csv (each customer with cluster)

models/task2_{kmeans,scaler}.joblib, models/task2_feature_names.json

Insurance:

models/insurance_best.joblib

Crime:

models/crime_svm.joblib

models/crime_trend_rf.joblib

models/feature_columns_trend.json

ğŸ§ª Quick Run Order (TL;DR)
Create env & install deps (see Environment Setup)

Retail: update DATA_PATH â†’ run notebook/script â†’ inspect Elbow â†’ set K_FINAL â†’ run PCA plot

Insurance: set INSURANCE_CSV â†’ run cells â†’ compare metrics â†’ save best

Crime: set CRIME_CSV â†’ run cells â†’ see reports/plots â†’ save models
